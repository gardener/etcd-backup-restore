#!/usr/bin/env bash
# SPDX-FileCopyrightText: 2024 SAP SE or an SAP affiliate company and Gardener contributors
#
# SPDX-License-Identifier: Apache-2.0
set -e

# For the test step concourse will set the following environment variables:
# SOURCE_PATH - path to component repository root directory.
if [[ $(uname) == 'Darwin' ]]; then
  READLINK_BIN="greadlink"
else
  READLINK_BIN="readlink"
fi

if [[ -z "${SOURCE_PATH}" ]]; then
  export SOURCE_PATH="$(${READLINK_BIN} -f "$(dirname ${0})/..")"
else
  export SOURCE_PATH="$(${READLINK_BIN} -f "${SOURCE_PATH}")"
fi

VCS="github.com"
ORGANIZATION="gardener"
PROJECT="etcd-backup-restore"
REPOSITORY=${VCS}/${ORGANIZATION}/${PROJECT}
URL=https://${REPOSITORY}.git
VERSION_FILE="$(${READLINK_BIN} -f "${SOURCE_PATH}/VERSION")"
VERSION="$(cat "${VERSION_FILE}")"
TEST_ID_PREFIX="etcdbr-test"
TM_TEST_ID_PREFIX="etcdbr-tm-test"

export GOBIN="${SOURCE_PATH}/bin"
export PATH="${GOBIN}:${PATH}"
# AWS_PAGER set to empty string to fix "Unable to redirect output to pager" error
# https://stackoverflow.com/questions/57953187/aws-cli-has-no-output/68361849#68361849
export AWS_PAGER=""
cd "${SOURCE_PATH}"

if [ "$USE_CC_SERVER_CACHE" == true ] ; then
  export CC_CACHE_FILE_FLAG="--cache-file dev/server.cache"
fi

##############################################################################

# Declare global variables
TEST_ID=
ETCD_VER=
ETCDBR_VER=
ETCD_DATA_DIR=
TEST_DIR=
TEST_RESULT=

set +e
test -d "${HOME}/.aws"
USE_EXISTING_AWS_SECRET=$?
set -e

function setup_test_environment() {
  setup_ginkgo
  setup_etcd
  setup_etcdbrctl
  setup_awscli
}

function setup_ginkgo() {
    echo "Installing Ginkgo..."
    go install github.com/onsi/ginkgo/ginkgo@v1.14.1 > /dev/null 2>&1
    ginkgo version
    echo "Successfully installed Ginkgo."
}

function setup_etcd(){
  echo "Downloading and installing etcd..."
  export ETCD_VER=v3.4.13
  if [[ $(uname) == 'Darwin' ]]; then
    curl -L https://storage.googleapis.com/etcd/${ETCD_VER}/etcd-${ETCD_VER}-darwin-amd64.zip -o etcd-${ETCD_VER}-darwin-amd64.zip
    unzip etcd-${ETCD_VER}-darwin-amd64.zip > /dev/null
    chmod +x ./etcd-${ETCD_VER}-darwin-amd64/etcd
    chmod +x ./etcd-${ETCD_VER}-darwin-amd64/etcdctl
    mv ./etcd-${ETCD_VER}-darwin-amd64/etcdctl ${GOBIN}/etcdctl
    mv ./etcd-${ETCD_VER}-darwin-amd64/etcd ${GOBIN}/etcd
    rm -rf ./etcd-${ETCD_VER}-darwin-amd64
    rm -rf etcd-${ETCD_VER}-darwin-amd64.zip
  else
    curl -L https://storage.googleapis.com/etcd/${ETCD_VER}/etcd-${ETCD_VER}-linux-amd64.tar.gz -o etcd-${ETCD_VER}-linux-amd64.tar.gz
    tar xzvf etcd-${ETCD_VER}-linux-amd64.tar.gz > /dev/null
    chmod +x ./etcd-${ETCD_VER}-linux-amd64/etcd
    chmod +x ./etcd-${ETCD_VER}-linux-amd64/etcdctl
    mv ./etcd-${ETCD_VER}-linux-amd64/etcdctl ${GOBIN}/etcdctl
    mv ./etcd-${ETCD_VER}-linux-amd64/etcd ${GOBIN}/etcd
    rm -rf ./etcd-${ETCD_VER}-linux-amd64
    rm -rf etcd-${ETCD_VER}-linux-amd64.tar.gz
  fi
  echo "Successfully installed etcd."
}

function setup_etcdbrctl(){
    echo "Installing etcdbrctl..."
    go build \
    -v \
    -o ${GOBIN}/etcdbrctl \
    -ldflags "-w -X ${REPOSITORY}/pkg/version.Version=${VERSION}" \
    -mod=vendor \
    main.go > /dev/null 2>&1
    chmod +x ${GOBIN}/etcdbrctl
    echo "Successfully installed etcdbrctl."
}

# More information at https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html
function setup_awscli() {
    if command -v aws > /dev/null; then
      return
    fi
    echo "Installing awscli..."
    # apt since the golang image that runs the integration tests is debian based
    if [[ $(uname) == 'Linux' ]]; then
      apt update && apt install -y curl unzip > /dev/null
      curl "https://awscli.amazonaws.com/awscli-exe-$(uname -s | tr '[:upper:]' '[:lower:]')-$(uname -m).zip" -o "awscliv2.zip" > /dev/null
      unzip awscliv2.zip > /dev/null
      ./aws/install -i /usr/local/aws-cli -b /usr/local/bin
      rm -rf awscliv2.zip aws
    else
      curl "https://awscli.amazonaws.com/AWSCLIV2.pkg" -o "AWSCLIV2.pkg"
      sudo installer -pkg AWSCLIV2.pkg -target /
      rm -rf AWSCLIV2.pkg
    fi
    echo "Successfully installed awscli."
}

function get_test_id() {
  git_commit=`git show -s --format="%H"`
  export TEST_ID=${TEST_ID_PREFIX}-${git_commit}
  echo "Test id: ${TEST_ID}"
}

function get_tm_test_id() {
  export TEST_ID=${TM_TEST_ID_PREFIX}-${GIT_REVISION}
  echo "Test id: ${TEST_ID}"
}

function create_etcd_data_directory() {
  export TEST_DIR=${PWD}/test/e2e_test_data
  export ETCD_DATA_DIR=${TEST_DIR}/etcd-data
  mkdir -p ${ETCD_DATA_DIR}
}

function get_aws_existing_region() {
  export REGION=`cat ${HOME}/.aws/config | grep -e "^.*region.*$" | sed "s/^.*region[ ]*=[ ]*//"`
}

#############################
#        AWS Setup          #
#############################

function write_aws_secret() {
  echo "Creating aws credentials for API access..."
  mkdir ${HOME}/.aws
  cat << EOF > ${HOME}/.aws/credentials
[default]
aws_access_key_id = $1
aws_secret_access_key = $2
EOF
  cat << EOF > ${HOME}/.aws/config
[default]
region = $3
EOF
  temp_dir=$(mktemp -d)
  credentials_file="${temp_dir}/credentials.json"
  cat <<EOF >"${credentials_file}"
{
  "accessKeyID": "$1",
  "secretAccessKey": "$2",
  "region": "$3"
}
EOF
  export AWS_APPLICATION_CREDENTIALS_JSON="${credentials_file}"
}

function create_aws_secret() {
  apt update && apt install -y pip > /dev/null
  pip install --break-system-packages gardener-cicd-cli > /dev/null
  echo "Fetching aws credentials from secret server..."
  export ACCESS_KEY_ID=`gardener-ci config $CC_CACHE_FILE_FLAG attribute --cfg-type aws --cfg-name etcd-backup-restore --key access_key_id`
  export SECRET_ACCESS_KEY=`gardener-ci config $CC_CACHE_FILE_FLAG attribute --cfg-type aws --cfg-name etcd-backup-restore --key secret_access_key`
  export REGION=`gardener-ci config $CC_CACHE_FILE_FLAG attribute --cfg-type aws --cfg-name etcd-backup-restore --key region`
  echo "Successfully fetched aws credentials from secret server."

  write_aws_secret "${ACCESS_KEY_ID}" "${SECRET_ACCESS_KEY}" "${REGION}"

  echo "Successfully created aws credentials."
}

function delete_aws_secret() {
  rm -rf ${HOME}/.aws
}

function create_s3_bucket() {
  echo "Creating S3 bucket ${TEST_ID} in region ${REGION}"
  aws s3api create-bucket --bucket ${TEST_ID} --region ${REGION} --create-bucket-configuration LocationConstraint=${REGION} --acl private
  # Block public access to the S3 bucket
  aws s3api put-public-access-block --bucket ${TEST_ID} --public-access-block-configuration "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
  # Deny non-HTTPS requests to the S3 bucket
  aws s3api put-bucket-policy --bucket ${TEST_ID} --policy "{\"Version\":\"2012-10-17\",\"Statement\":[{\"Effect\":\"Deny\",\"Principal\":\"*\",\"Action\":\"s3:*\",\"Resource\":[\"arn:aws:s3:::${TEST_ID}\",\"arn:aws:s3:::${TEST_ID}/*\"],\"Condition\":{\"Bool\":{\"aws:SecureTransport\":\"false\"},\"NumericLessThan\":{\"s3:TlsVersion\":\"1.2\"}}}]}"
}

function delete_s3_bucket() {
  echo "Deleting S3 bucket ${TEST_ID}"
  aws s3 rb s3://${TEST_ID} --force
}

function setup-aws-infrastructure() {
  echo "Setting up AWS infrastructure..."
  if [[ "${USE_EXISTING_AWS_SECRET}" == "1" ]]; then
    create_aws_secret
  else
    get_aws_existing_region
  fi
  create_s3_bucket
  echo "AWS infrastructure setup completed."
}

function cleanup-aws-infrastructure() {
  echo "Cleaning up AWS infrastructure..."
  delete_s3_bucket
  if [[ "${USE_EXISTING_AWS_SECRET}" == "1" ]]; then
    delete_aws_secret
  fi
  echo "AWS infrastructure cleanup completed."
}

function remove-etcd-data-directory() {
   echo "Removing ETCD Data Directory"
   rm -rf ${ETCD_DATA_DIR}
 }

#############################
#        Azure Setup        #
#############################
function create_azure_secret() {
  echo "Creating Azure secret"
}

#############################
#        GCP Setup          #
#############################
function create_gcp_secret() {
echo "Creating GCP secret"
}

#############################
#        Openstack Setup    #
#############################
function create_openstack_secret() {
echo "Creating Openstack secret"
}

##############################################################################
function setup_test_cluster() {
  get_test_id
  setup-aws-infrastructure
  create_gcp_secret
  create_azure_secret
  create_openstack_secret
  create_etcd_data_directory
}

function cleanup_test_environment() {
  cleanup-aws-infrastructure
  remove-etcd-data-directory
}

###############################################################################

function run_test_as_processes() {
  setup_test_environment
  echo "Setting up test cluster..."
  setup_test_cluster

  echo "Starting integration tests..."
  cd test/e2e/integration

  set +e
  ginkgo -r -mod=vendor
  TEST_RESULT=$?
  set -e

  echo "Done with integration tests."

  echo "Deleting test enviornment..."
  cleanup_test_environment
  echo "Successfully completed all tests."

  if [ ${TEST_RESULT} -ne 0 ]; then
    echo "Printing etcdbrctl.log:"
    cat ${TEST_DIR}/etcdbrctl.log
  fi
}

function run_test_on_cluster() {
  if ! [ -x "$(command -v ginkgo)" ]; then
    setup_ginkgo
  fi

  export TEST_ID=${STORAGE_CONTAINER}
  if [ "$STORAGE_CONTAINER" == "" ]; then
    setup_awscli
    get_test_id
    setup-aws-infrastructure
  fi

  export ETCD_VERSION=${ETCD_VERSION:-"v3.4.13-bootstrap-1"}
  echo "Etcd version: ${ETCD_VERSION}"

  export ETCDBR_VERSION=${ETCDBR_VERSION:-${ETCDBR_VER:-"v0.12.1"}}
  echo "Etcd-backup-restore version: ${ETCDBR_VERSION}"

  echo "Starting integration tests on k8s cluster."

  set +e

  if [ -r "$INTEGRATION_TEST_KUBECONFIG" ]; then
    KUBECONFIG=$INTEGRATION_TEST_KUBECONFIG STORAGE_CONTAINER=$TEST_ID ginkgo -v -timeout=15m -mod=vendor test/e2e/integrationcluster
    TEST_RESULT=$?
    echo "Successfully completed all tests."
  else
    echo "Invalid kubeconfig for integration test $INTEGRATION_TEST_KUBECONFIG"
    TEST_RESULT=255
  fi

  set -e

  echo "Done with integration test on k8s cluster."

  if [ "$STORAGE_CONTAINER" == "" ]; then
    echo "Deleting test bucket..."
    cleanup-aws-infrastructure
  fi
}

function run_test_on_tm() {
  if [ "$ACCESS_KEY_ID" == "" ] || [ "$SECRET_ACCESS_KEY_B64" == "" ] || [ "$AWS_REGION" == "" ] ; then
    echo "AWS S3 credentials unavailable. Exiting."
    exit 1
  fi
  export SECRET_ACCESS_KEY=`echo $SECRET_ACCESS_KEY_B64 | base64 -d`
  export REGION=$AWS_REGION

  get_tm_test_id
  export STORAGE_CONTAINER=$TEST_ID
  export ETCDBR_VER=$EFFECTIVE_VERSION

  setup_awscli
  write_aws_secret "${ACCESS_KEY_ID}" "${SECRET_ACCESS_KEY}" "${REGION}"
  create_s3_bucket

  export INTEGRATION_TEST_KUBECONFIG=$TM_KUBECONFIG_PATH/shoot.config
  echo "Starting integration tests on TM cluster $PROJECT_NAMESPACE/$SHOOT_NAME."
  run_test_on_cluster
  echo "Done with integration test on TM cluster."
  cleanup-aws-infrastructure
}

case $1 in
  tm)
    run_test_on_tm
    ;;
  cluster)
    run_test_on_cluster
    ;;
  *)
    run_test_as_processes
    ;;
esac

exit $TEST_RESULT
